Hamiltonian Monte Carlo
===============================================================================
author: Jonas Moss
date: Mars 2018
autosize: true

The Hamiltonian
===============================================================================

* $p_{i}$: The ith momentum component ($mv$).
* $q_{i}$: The ith position component.
* $\mathcal{H}$: The Hamiltonian.
* Hamiltonian dynamics:
  * $\frac{dp_{i}}{dt} = \frac{\partial \mathcal{H}}{\partial q_{i}}$
  * $\frac{dq_{i}}{dt} = -\frac{\partial \mathcal{H}}{\partial p_{i}}$

What about the physics?
===============================================================================
* Assume $\mathcal{H} = U(q) + K(p)$ 
* $U$ is the *potential energy* of our particle in position $q$.
* $K$ is the *kinetic energy* of our particle with momentum $p$.
* Newton's 2nd law: $F=ma=\frac{dq}{dt}$
  * Potential energy: Think of a "gravity well". The potential energy
    is zero at the bottom of the well.
* Velocity: $\frac{dp_{i}}{dt} = v$
  * Kinetic energy: $K(q) = \frac{1}{2}mv^2$

Hamiltonian dynamics
===============================================================================
* Restatement of Hamiltonian dynamics:
  * $F = \frac{dp_{i}}{dt} = \frac{\partial U}{\partial q_{i}}$
  * $v = \frac{dq_{i}}{dt} = -\frac{\partial K}{\partial p_{i}}$
* Energy is conserved: Think of a frictionless surface 
  with no air resistance.
* Consequence: When the potential energy is low, the kinetic energy is high. 
  The particle will always move about.
* Running the Hamiltionan dynamics explores an *energy level* of the 
  $p\times q$ phase space. 
  
Hamiltionians in probability.
===============================================================================  
* Recall that $\mathcal{H} = U(q) + K(p)$ 
* Let $U(q) = -\log\pi(q)$: The potential energy surface is the nagative 
  logarithm of the target density.
* Let $K(p) = -\log\pi(p)$: The kinetic energy is the negative logarithm of the 
  momentom proposal density.
* The moment proposal density is typically normal, so that
  $K(p) \propto \frac{1}{2m}||q||^2$ for some mass $m$. Provides a good 
  argument for using a normal moment proposal.

Idealized Hamiltonian Monte Carlo
===============================================================================
For an initial position $p^{0}$, repeat a large number of times.

1. Sample a momentum from $\pi(q)$, the moment proposal density.
2. Integrate the Hamiltonian dynamics for some time.
3. Use the position variable as $p^{i+1}$.

Problem: Explicit solutions are rare.
===============================================================================
* Systems of differential equations are almost never analytically.
* Honorable exception: Linear systems are solvable.
* We have to numerically integrate the Hamiltionan system!
* Adds several complications: Must choose tuning parameters.
* (++) Books have been written on integrating Hamiltonian systems.
  * Look up "symplectic integration", "geometric integration", 
    "integrating Hamiltonian".
  * Connected to classical problems such as the n-body problem.

Normal distribution: A linear problem
===============================================================================
* $U(q) = - \log(\pi(q)) = \frac{q^2}{2}$: Normal target distribution.
* $K(p) = - \log(\pi(p)) = \frac{p^2}{2}$: Normal proposal distribution.

System reduces to

\[
\begin{array}{ccc}
\frac{dq_{i}}{dt} & = & p\\
\frac{dp_{i}}{dt} & = & q
\end{array}
\]

Normal distribution: A harmonic oscillator
===============================================================================

Solutions: 

\[
\begin{array}{ccc}
q\left(t\right) & = & r\cos\left(a+t\right)\\
p\left(t\right) & = & -r\sin\left(a+t\right)
\end{array}
\]

Circle with radius $r = \sqrt(p^2 + q^2)$ and shift $a$. 

The energy is $E = -\frac{1}{2}(p^2 + q^2) = -\frac{1}{2}r^2$

Normal distribution: A circle in phase space
===============================================================================

```{r, echo = FALSE}
r = 3
t = seq(0, 10, by = 0.01)
a = 2
plot(r*cos(a + t), -r*sin(a + t), type = "l", bty = "l", xlab = "q", 
     ylab = "p", main = paste0("Energy set (r = ", r, ")"))
```

What about the energy distribution?
===============================================================================
* The energy level is distributed according to $-\frac{1}{2}\chi^2(2)$.
* Alternative sampling strategy: 
  1. Sample $E$ from $-\frac{1}{2}\chi^2(2)$, 
  2. $(q, p)$ uniformly from the circle with radius $\sqrt(-2E)$.  
  3. Project on $q$.
  
Energy distribution, R code
===============================================================================
```{r}
set.seed(313)
n = 10000
E = -1/2*rchisq(n, 2)
theta = runif(n, 0, 2*pi)
q = sqrt(-2*E)*cos(theta)
p = -sqrt(-2*E)*sin(theta)
```  

Energy distribution, density
===============================================================================
```{r, echo = FALSE}
plot(kdensity::kdensity(q, adjust = 2))
x = seq(-5, 5, by = 0.01)
lines(x, dnorm(x), col = "red")
```  

Monte Carlo variant
===============================================================================
* Monte Carlo change:
  1. Sample $E_{i+1}$ from $-\frac{1}{2}(\chi^2(1) + q_{i}^2)$, 
  2. $(q, p)$ uniformly from the circle with radius $\sqrt(-2E)$.  
  3. Project on $q$.
* Note that $E ~ -\frac{1}{2}\chi^2(2)$ in the limit when $q_{i}$.
* And vice versa!

Monte Carlo variant, R  code
===============================================================================
```{r}
n = 1000
q = rep(0, n) # Positions, normal 
E = rep(0, n) # Energies, -1/2*chi^2(2) 
p = rnorm(n, mean = 0, sd = 1)
theta = runif(n, 0, 2*pi) 

for(i in 2:n) {
  E[i] = -1/2*(q[i - 1]^2 + p[i]^2)
  q[i] = sqrt(-2*E[i])*cos(theta[i])
}
```  

Monte Carlo variant, ACF
===============================================================================
```{r, echo = FALSE}
plot(acf(q))
```  

Monte Carlo variant, density
===============================================================================
```{r, echo = FALSE}
plot(kdensity::kdensity(q, adjust = 2))
x = seq(-5, 5, by = 0.01)
lines(x, dnorm(x), col = "red")
```  

Monte Carlo variant, energies
===============================================================================
```{r, echo = FALSE}
hist(E, breaks = 100, freq = FALSE, main = "Energy distribution")
x = seq(-10, 0, by = 0.01)
lines(x, 2*dchisq(-2*x, 2), col = "red")
```  

Euler's method 
===============================================================================
Light and simple differential equation solver. 
\[
\begin{array}{ccc}
p_{i}\left(t+\epsilon\right) & = & p_{i}\left(t\right)+\epsilon\frac{dp_{i}}{dt}\left(t\right)\\
q_{i}\left(t+\epsilon\right) & = & p_{i}\left(t\right)+\epsilon\frac{dq_{i}}{dt}\left(t\right)
\end{array}
\]

For Hamiltonian dynamics:
\[
\begin{array}{ccc}
p_{i}\left(t+\epsilon\right) & = & p_{i}\left(t\right)-\epsilon\frac{dU}{dq_{i}}\left(t\right)\\
q_{i}\left(t+\epsilon\right) & = & q_{i}\left(t\right)+\epsilon\frac{dK}{dp_{i}}\left(t\right)
\end{array}
\]

Euler's method is unacceptable!
===============================================================================
```{r, echo = FALSE}
a = 0
q0 = sqrt(2)/2
p0 = sqrt(2)/2
r = sqrt(p0^2 + q0^2)

p = function(t) r*cos(a + t)
q = function(t) -r*sin(a + t)

eps = 0.1
n = 100
ps = rep(0, n + 1)
ps[1] = p0
qs = rep(0, n + 1)
qs[1] = q0

t = 0
for(i in 1:n) {
  ps[i + 1] = ps[i] - eps*qs[i]
  qs[i + 1] = qs[i] + eps*ps[i] 
  t = t + eps
}

t = seq(0, 2*pi, by = 0.01)
plot(r*cos(a + t), -r*sin(a + t), type = "l", bty = "l", xlab = "q", 
     ylab = "p", main = paste0("Energy set (r = ", r, "; eps = ", eps,
                               "; n = ", n, ")"), 
     xlim = c(-2, 2),
     ylim = c(-2, 2))
points(qs, ps, type = "b")
```  

The Leapfrog
===============================================================================

A *symplectic integrator*. Known as the velocity vervlet.
\[
\begin{eqnarray*}
p_{i}\left(t+\frac{\epsilon}{2}\right) & = & p_{i}\left(t\right)-\frac{\epsilon}{2}\frac{dU}{dq_{i}}\left(q_{i}\left(t\right)\right)\\
q_{i}\left(t+\epsilon\right) & = & q_{i}\left(t\right)+\epsilon\frac{dK}{dp_{i}}\left(p_{i}\left(t+\frac{\epsilon}{2}\right)\right)\\
p_{i}\left(t+\epsilon\right) & = & p_{i}\left(t+\frac{\epsilon}{2}\right)-\epsilon\frac{dU}{dq_{i}}\left(q_{i}\left(t+\epsilon\right)\right)
\end{eqnarray*}
\]

Some Motivation
===============================================================================
* Euler: $y(t+\epsilon) = y(t) + \epsilon f(y(t))$; based on $g'(x)
  \approx \frac{1}{\epsilon}(g(x + \epsilon) - g(x))$ 
* Numerical differentation of the form 
  $\frac{1}{\epsilon}(g(x + \epsilon) - g(x))$ approximates the derivative at 
  the midpoint: $g'(x + \frac{1}{2}\epsilon)$ Think about the words 
  "Intermediate Value Theorem".
* Hence $y(t+\epsilon) = y(t) + \epsilon f(y(t + \epsilon/2))$ should be more
  accurate. (And it is!) This method is called midpoint Euler (MAT-INF1100).
* Using this reasoning on the Hamiltonian system yields the leapfrog.

Performance of Leapfrog (eps = 1)
===============================================================================
```{r, echo = FALSE}
a = 0
q0 = sqrt(2)/2
p0 = sqrt(2)/2
r = sqrt(p0^2 + q0^2)

p = function(t) r*cos(a + t)
q = function(t) -r*sin(a + t)

eps = 1
n = 90
ps = rep(0, n + 1)
ps[1] = p0
qs = rep(0, n + 1)
qs[1] = q0

t = 0
for(i in 1:n) {
  p_temp = ps[i] - eps/2*qs[i]
  qs[i + 1] = qs[i] + eps*p_temp 
  ps[i + 1] = p_temp - eps/2*qs[i + 1]
  t = t + eps
}

t = seq(0, 2*pi, by = 0.01)
plot(r*cos(a + t), -r*sin(a + t), type = "l", bty = "l", xlab = "q", 
     ylab = "p", main = paste0("Energy set (r = ", r, "; eps = ", eps,
                               "; n = ", n, ")"), 
     xlim = c(-2, 2),
     ylim = c(-2, 2))
points(qs, ps, type = "b")
```  

Performance of Leapfrog (eps = 0.1)
===============================================================================
```{r, echo = FALSE}
a = 0
q0 = sqrt(2)/2
p0 = sqrt(2)/2
r = sqrt(p0^2 + q0^2)

p = function(t) r*cos(a + t)
q = function(t) -r*sin(a + t)

eps = 0.1
n = 60
ps = rep(0, n + 1)
ps[1] = p0
qs = rep(0, n + 1)
qs[1] = q0

t = 0
for(i in 1:n) {
  p_temp = ps[i] - eps/2*qs[i]
  qs[i + 1] = qs[i] + eps*p_temp 
  ps[i + 1] = p_temp - eps/2*qs[i + 1]
  t = t + eps
}

t = seq(0, 2*pi, by = 0.01)
plot(r*cos(a + t), -r*sin(a + t), type = "l", bty = "l", xlab = "q", 
     ylab = "p", main = paste0("Energy set (r = ", r, "; eps = ", eps,
                               "; n = ", n, ")"), 
     xlim = c(-2, 2),
     ylim = c(-2, 2))
points(qs, ps, type = "b")
```  

Properties of Leapfrog
===============================================================================
1. Second order method: In general better than Euler. 
  * Measures how much the error grows in terms of $\epsilon$. First order has
    error $O(\epsilon)$ second order $O(\epsilon^2)$ etc.
2. Is time reversible:
  * You can recover the trajectory by reversing the signs in the algorithm.
3. Conserves volume:
  * If a section of phase-space is transformed by Hamiltonian dynamics, the
    volume is preserved.
  * The Leapfrog preserves volume as well!
  * Puts severe restrictions on the ability of leapfrog to diverge.

Choosing L and epsilon
===============================================================================
* $L$: The length of the trajectory.
  * Too large makes the sampler more Metropolisy: Uses a long time to explore an
    energy level.
  * Too large takes a long time to compute.
  * Large $L$ will transfer you back to the beginning.
* $\epsilon$: The step-size used in the leapfrog integrator.
  * Too small epsilon is inefficient; too large is inexact.
* Hoffman, Gelman (2014): No-U-Turn Sampler
  * Selects $L$ and $\epsilon$ adaptively while preserving time-reversibility.
  * Is used in `STAN`.
  
Fixing the inexactness
===============================================================================
We use Metropolis to fix the inexactness of the method. Describe.

How many samples to take from a trajectory.
===============================================================================